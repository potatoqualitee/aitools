{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "╔═══════════════════════════════════════════════════════════════════════════════╗\n",
        "║                                                                               ║\n",
        "║   ██████╗ ██████╗ ███████╗    ████████╗ ██████╗     █████╗ ██╗                ║\n",
        "║   ██╔══██╗██╔══██╗██╔════╝    ╚══██╔══╝██╔═══██╗   ██╔══██╗██║                ║\n",
        "║   ██████╔╝██║  ██║█████╗         ██║   ██║   ██║   ███████║██║                ║\n",
        "║   ██║     ██║  ██║██╔══╝         ██║   ██║   ██║   ██╔══██║██║                ║\n",
        "║   ██║     ██████╔╝██║            ██║   ╚██████╔╝   ██║  ██║██║                ║\n",
        "║   ╚═╝     ╚═════╝ ╚═╝            ╚═╝    ╚═════╝    ╚═╝  ╚═╝╚═╝                ║\n",
        "║                                                                               ║\n",
        "║          From Structured Output to \"Just Tell the AI\"                         ║\n",
        "║                                                                               ║\n",
        "║                    Unattended 2025 - Chrissy LeMaire                          ║\n",
        "║                                                                               ║\n",
        "╚═══════════════════════════════════════════════════════════════════════════════╝\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## The Evolution\n",
        "\n",
        "> \"I used to spend hours teaching you how to parse PDFs into structured output...\"\n",
        "\n",
        "**Then:** JSON schemas, strict validation, prompt engineering, field mapping, error handling\n",
        "\n",
        "**Now:** `\"Review this PDF, create normalized tables, and import the data\"`\n",
        "\n",
        "Let's see Claude do the heavy lifting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table><thead><tr><th><i>key</i></th><th>value</th></tr></thead><tbody><tr><td><div class=\"dni-plaintext\"><pre>FullName</pre></div></td><td><div class=\"dni-plaintext\"><pre>AITools.DefaultTool</pre></div></td></tr><tr><td><div class=\"dni-plaintext\"><pre>Value</pre></div></td><td><div class=\"dni-plaintext\"><pre>Copilot</pre></div></td></tr></tbody></table><style>\r\n",
              ".dni-code-hint {\r\n",
              "    font-style: italic;\r\n",
              "    overflow: hidden;\r\n",
              "    white-space: nowrap;\r\n",
              "}\r\n",
              ".dni-treeview {\r\n",
              "    white-space: nowrap;\r\n",
              "}\r\n",
              ".dni-treeview td {\r\n",
              "    vertical-align: top;\r\n",
              "    text-align: start;\r\n",
              "}\r\n",
              "details.dni-treeview {\r\n",
              "    padding-left: 1em;\r\n",
              "}\r\n",
              "table td {\r\n",
              "    text-align: start;\r\n",
              "}\r\n",
              "table tr { \r\n",
              "    vertical-align: top; \r\n",
              "    margin: 0em 0px;\r\n",
              "}\r\n",
              "table tr td pre \r\n",
              "{ \r\n",
              "    vertical-align: top !important; \r\n",
              "    margin: 0em 0px !important;\r\n",
              "} \r\n",
              "table th {\r\n",
              "    text-align: start;\r\n",
              "}\r\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Anthropic's having outages. PIVOTTT\n",
        "Set-AIToolDefault -Tool Copilot\n",
        "\n",
        "# Setup\n",
        "$PSDefaultParameterValues[\"Invoke-AITool:Raw\"] = $true\n",
        "$PSDefaultParameterValues[\"Invoke-AITool:Model\"] = \"claude-sonnet-4.5\"\n",
        "\n",
        "$sqlInstance = \"localhost\"\n",
        "$database = \"tempdb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [],
      "source": [
        "# Let's see what we're working with\n",
        "Start-Process ./Tests/pdf/immunization.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Schema Design\n",
        "\n",
        "No pre-planning. No schema files. Just ask Claude to analyze the PDF and design proper normalized tables.\n",
        "\n",
        "> \"Show me your work, then create it.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [],
      "source": [
        "$designPrompt = @\"\n",
        "Review Tests/pdf/immunization.pdf carefully and design a normalized database schema.\n",
        "\n",
        "Requirements:\n",
        "- Create properly normalized tables (at least 2 tables with foreign key relationship)\n",
        "- Use best practices for data types, constraints, and indexing\n",
        "- Target DB: SQL Server, localhost, windows auth, tempdb\n",
        "\n",
        "Output:\n",
        "1. First, explain your design decisions (table structure, why you normalized this way)\n",
        "2. Then provide the complete T-SQL DDL to create the tables\n",
        "3. Execute ONLY DDL against local SQL Server\n",
        "\"@\n",
        "\n",
        "Invoke-AITool -Prompt $designPrompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Extract (The Annoying ETL Part)\n",
        "\n",
        "Now the classic ETL challenge: extract data from the PDF and insert into normalized tables.\n",
        "\n",
        "First pass: **Extract exactly as-is.** Bad data and all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [],
      "source": [
        "$extractPrompt = \"Extract the data from /Tests/pdf/immunization.md\n",
        "\n",
        "I have vaccine tables in tempdb on localhost (sql server/windows auth),\n",
        "figure out the structure, insert the data from the PDF then show me what\n",
        "you inserted\"\n",
        "\n",
        "Invoke-AITool -Prompt $extractPrompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Go look in SSMS, notice anything wrong?\n",
        "\n",
        "The data is in there exactly as the PDF showed it. But there might be problems...\n",
        "\n",
        "---\n",
        "## Part 3: Upsert with AI Data Quality Review\n",
        "\n",
        "Now the magic. Ask Claude to review the data, identify problems, fix them, AND document what it found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [],
      "source": [
        "Invoke-AITool -Prompt C:\\github\\aitools\\unattended.md -Tool Claude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 4: Data Quality Report\n",
        "\n",
        "Generate a markdown report documenting all the issues found. \n",
        "\n",
        "This is your audit trail - proof that AI caught problems human review might miss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "pwsh"
        },
        "polyglot_notebook": {
          "kernelName": "pwsh"
        }
      },
      "outputs": [],
      "source": [
        "$reportPrompt = @\"\n",
        "Review /Tests/pdf/immunization.pdf carefully and generate a data quality report.\n",
        "\n",
        "Analyze the document thoroughly for:\n",
        "- Missing or incomplete information\n",
        "- Suspicious or potentially incorrect values\n",
        "- Format issues\n",
        "- Any other data quality concerns\n",
        "\n",
        "Output a well-formatted Markdown report with:\n",
        "- Executive summary\n",
        "- Table of issues found (columns: Field, Value in PDF, Issue, Recommended Fix)\n",
        "- Confidence level for each finding\n",
        "- Recommendations for human review\n",
        "\n",
        "Be thorough - this report helps humans catch shit data before it pollutes the database.\n",
        "\"@\n",
        "\n",
        "$report = Invoke-AITool -Prompt $reportPrompt\n",
        "\n",
        "# Save the report\n",
        "$report | Set-Content ./Tests/pdf/data_quality_report.md\n",
        "Write-Host \"Report saved to: ./Tests/pdf/data_quality_report.md\" -ForegroundColor Green\n",
        "\n",
        "# Display it\n",
        "$report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## The Point\n",
        "\n",
        "### What I Used to Teach\n",
        "```powershell\n",
        "# 1. Define rigid JSON schema (50 lines)\n",
        "# 2. Configure structured output API\n",
        "# 3. Write validation rules (100+ lines)\n",
        "# 4. Build table mappings\n",
        "# 5. Handle edge cases\n",
        "# 6. Debug parsing failures\n",
        "# 7. Hope you thought of everything\n",
        "```\n",
        "\n",
        "### What I Do Now\n",
        "```powershell\n",
        "\"Review this PDF, create normalized tables, import the data, \n",
        " find the problems, fix them, and document what you found.\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Why This Works\n",
        "\n",
        "| Traditional ETL | AI-Assisted ETL |\n",
        "|-----------------|----------------|\n",
        "| Check against rules I thought of | Notices things I didn't think to check |\n",
        "| Rigid schema matching | Semantic understanding |\n",
        "| Fails on edge cases | Adapts to messy data |\n",
        "| Silent data corruption | Documents concerns for review |\n",
        "\n",
        "**The key insight:** AI catches semantic issues that rule-based validation can't.\n",
        "\n",
        "\"Labrador\" is a valid breed. Traditional validation would pass it.\n",
        "\n",
        "But AI looks at the *whole picture* and knows it doesn't quite add up."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".NET (C#)",
      "language": "C#",
      "name": ".net-csharp"
    },
    "language_info": {
      "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
      "kernelInfo": {
        "defaultKernelName": "csharp",
        "items": [
          {
            "aliases": [],
            "name": "csharp"
          },
          {
            "aliases": [],
            "languageName": "pwsh",
            "name": "pwsh"
          }
        ]
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
